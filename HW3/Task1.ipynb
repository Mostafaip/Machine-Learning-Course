{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d76350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import scipy \n",
    "import sklearn\n",
    "from collections import Counter\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from scipy import spatial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "850b8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv',header=None)\n",
    "labels = pd.read_csv('label.csv',names=['label'],header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc3a6b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f2963d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split( data, test_size=0.08, random_state=42)\n",
    "train_labels, test_labels = train_test_split( labels, test_size=0.08, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fafd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    \n",
    "    def calculate_SSE(self, centroid_value_dict, centroid_dict,data):\n",
    "        sse_data = 0\n",
    "        for i in centroid_dict:\n",
    "            sse_cluster = 0\n",
    "\n",
    "            for j in centroid_dict[i]:\n",
    "                dp = list(data.iloc[int(j)])\n",
    "                for a,b in zip(centroid_value_dict[i],dp):\n",
    "                    sse_cluster += (a-b)**2\n",
    "            sse_data+=sse_cluster\n",
    "        return sse_data    \n",
    "    \n",
    "    def Initialize_Centroids(self,data,K):\n",
    "        m = data.shape[0]\n",
    "        centroid_value_dict={}\n",
    "        for i in range(K):\n",
    "            r = np.random.randint(0, m-1)\n",
    "            centroid_value_dict[i] = data.iloc[r]\n",
    "        return centroid_value_dict\n",
    "    \n",
    "    def jaccard_similarity(self,centroid, dp):\n",
    "        intersection = len(list(set(centroid).intersection(dp)))\n",
    "        union = (len(set(centroid)) + len(set(dp))) - intersection\n",
    "        return float(intersection) / union\n",
    "\n",
    "    def train_Kmeans(self,data,K,max_iter=20,mode=1,tol=10):\n",
    "        #Mode = 1 => Euclidean np.linalg.norm(x-list(data.iloc[i,:]))\n",
    "        #Mode = 2 => Jaccard\n",
    "        #Mode = 3 => Cosine\n",
    "        centroid_value_dict = self.Initialize_Centroids(data,K)\n",
    "        new_centroid_value_dict = {}\n",
    "        count = 0\n",
    "        centroid_dict = {}\n",
    "        convergence = False\n",
    "        while((count<max_iter) and not convergence):\n",
    "            \n",
    "            for i in list(centroid_value_dict.keys()):\n",
    "                centroid_dict[i]=[]\n",
    "            for i in range(data.shape[0]):\n",
    "                x = data.iloc[i]\n",
    "                if mode==1 :\n",
    "                    distance_measure = [np.linalg.norm(x-centroid_value_dict[j])  for j in centroid_value_dict]\n",
    "                    idx = np.argmin(distance_measure)\n",
    "                    centroid_dict[idx].append(i)\n",
    "                elif mode==2 :\n",
    "                    distance_measure = [self.jaccard_similarity(list(x),centroid_value_dict[j]) for j in centroid_value_dict]\n",
    "                    idx = np.argmax(distance_measure)\n",
    "                    centroid_dict[idx].append(i)\n",
    "                elif mode==3 :\n",
    "                    distance_measure = [1-scipy.spatial.distance.cosine(x,list(centroid_value_dict[j]))  for j in centroid_value_dict]\n",
    "                    idx = np.argmax(distance_measure)\n",
    "                    centroid_dict[idx].append(i)\n",
    "                \n",
    "                prev_centroids=dict(centroid_value_dict)\n",
    "                \n",
    "            \n",
    "            for i in centroid_dict:\n",
    "                if len(centroid_dict[i]):\n",
    "                    dps_centroid = centroid_dict[i]\n",
    "                    centroid_value_dict[i] = np.average(data.iloc[dps_centroid],axis=0)\n",
    "            \n",
    "            \n",
    "            current_tol=-1\n",
    "            for i in centroid_value_dict:\n",
    "                prev_centroid_point = prev_centroids[i]\n",
    "                new_centroid_point = centroid_value_dict[i]\n",
    "                change = np.sum(np.absolute(new_centroid_point-prev_centroid_point))\n",
    "                current_tol = max(change, current_tol)\n",
    "                \n",
    "            print(\"Tolerance for the Iteration \",count,\": \",current_tol)\n",
    "            \n",
    "            count+=1\n",
    "            if (current_tol<10):\n",
    "                convergence = True\n",
    "                break\n",
    "           # print(\"KMeans Iteration\",count)\n",
    "        return centroid_value_dict,centroid_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "790c6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cluster_labels(C, S, labels):\n",
    "    '''\n",
    "    Input : C -> Centroids\n",
    "            S -> Set of Indicies corresponding to Centroid C\n",
    "            data -> Data used to form clusters\n",
    "    Output : Returns an array of size K having labels based on majority voting in the cluster\n",
    "    '''\n",
    "    cluster_labels = np.zeros(10,dtype=int)\n",
    "    for c in C:\n",
    "        labels_of_points = []\n",
    "        for point in S[c]:\n",
    "            labels_of_points.extend(labels.iloc[point])\n",
    "        counter = Counter(labels_of_points)\n",
    "        try:\n",
    "            cluster_labels[c] = max(counter, key=counter.get)\n",
    "        except:\n",
    "            cluster_labels[c] = np.random.randint(0,9)\n",
    "    return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "974d587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(centroid, dp):\n",
    "        intersection = len(list(set(centroid).intersection(dp)))\n",
    "        union = (len(set(centroid)) + len(set(dp))) - intersection\n",
    "        return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf5ae9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(centroids, centroid_Labels, test_data, true_labels, mode=1):\n",
    "    y_true = list(true_labels['label']);\n",
    "    y_pred = []\n",
    "    for index in range(test_data.shape[0]):\n",
    "        featureset = test_data.iloc[index]\n",
    "        if mode==1:\n",
    "            distances = [np.linalg.norm(featureset - centroids[centroid]) for centroid in centroids]\n",
    "            classification = distances.index(min(distances))\n",
    "            y_pred.append(centroid_Labels[classification])\n",
    "        elif mode==2:\n",
    "            similarity = [jaccard_similarity(featureset, centroids[centroid]) for centroid in centroids]\n",
    "            classification = similarity.index(max(similarity))\n",
    "            y_pred.append(centroid_Labels[classification]) \n",
    "        elif mode==3:\n",
    "            similarity = [1 - spatial.distance.cosine(featureset, centroids[centroid]) for centroid in centroids]\n",
    "            classification = similarity.index(max(similarity))\n",
    "            y_pred.append(centroid_Labels[classification])\n",
    "    denominator = test_data.shape[0]\n",
    "    correctly_classified = 0\n",
    "    for i in range(0,len(y_pred)):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            correctly_classified += 1\n",
    "    accuracy = correctly_classified/denominator\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10dd851f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerance for the Iteration  0 :  24214.56341463415\n",
      "Tolerance for the Iteration  1 :  4763.257874260815\n",
      "Tolerance for the Iteration  2 :  2509.0703703703703\n",
      "Tolerance for the Iteration  3 :  2362.1920058211854\n",
      "Tolerance for the Iteration  4 :  2301.3604302749736\n",
      "Tolerance for the Iteration  5 :  2918.787544367864\n",
      "Tolerance for the Iteration  6 :  2801.867152455232\n",
      "Tolerance for the Iteration  7 :  2158.803415347659\n",
      "Tolerance for the Iteration  8 :  1284.4762349864732\n",
      "Tolerance for the Iteration  9 :  1001.2348165715193\n",
      "Tolerance for the Iteration  10 :  844.4600780649359\n",
      "Tolerance for the Iteration  11 :  583.1973315528203\n",
      "Tolerance for the Iteration  12 :  462.0270072790804\n",
      "Tolerance for the Iteration  13 :  257.77052871492793\n",
      "Tolerance for the Iteration  14 :  221.85688946889547\n",
      "Tolerance for the Iteration  15 :  189.219936314551\n",
      "Tolerance for the Iteration  16 :  208.69735133463877\n",
      "Tolerance for the Iteration  17 :  129.64466081782382\n",
      "Tolerance for the Iteration  18 :  88.73939208224498\n",
      "Tolerance for the Iteration  19 :  59.32869628714611\n",
      "Tolerance for the Iteration  20 :  43.77957020389242\n",
      "Tolerance for the Iteration  21 :  37.98292098197156\n",
      "Tolerance for the Iteration  22 :  0.0\n"
     ]
    }
   ],
   "source": [
    "model1 = KMeans()\n",
    "centroids1,clusters1 = model1.train_Kmeans(data,10, max_iter=100,mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a58e17d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Euclidean_SSE = model1.calculate_SSE(centroids1,clusters1,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f6c16ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean SSE: 25454304340.476444\n"
     ]
    }
   ],
   "source": [
    "print(\"Euclidean SSE:\",Euclidean_SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38acedb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 0, 7, 3, 4, 5, 6, 1, 8])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_labels1 = predict_cluster_labels(centroids1,clusters1,labels)\n",
    "cluster_labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfdc8125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.645"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_Euclidean = accuracy(centroids1, cluster_labels1,test_data,test_labels)\n",
    "Accuracy_Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a16f221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerance for the Iteration  0 :  36315.06580366775\n",
      "Tolerance for the Iteration  1 :  10332.198479152887\n",
      "Tolerance for the Iteration  2 :  9107.486706218413\n",
      "Tolerance for the Iteration  3 :  9924.950532552659\n",
      "Tolerance for the Iteration  4 :  11852.857133333333\n",
      "Tolerance for the Iteration  5 :  3054.852996204934\n",
      "Tolerance for the Iteration  6 :  1220.5438472775566\n",
      "Tolerance for the Iteration  7 :  936.9166565262077\n",
      "Tolerance for the Iteration  8 :  965.0841952191233\n",
      "Tolerance for the Iteration  9 :  1482.9759400215748\n",
      "Tolerance for the Iteration  10 :  1035.716604835924\n",
      "Tolerance for the Iteration  11 :  368.3271873965442\n",
      "Tolerance for the Iteration  12 :  324.10659470595925\n",
      "Tolerance for the Iteration  13 :  0.0\n"
     ]
    }
   ],
   "source": [
    "model2 = KMeans()\n",
    "centroids2,clusters2 = model2.train_Kmeans(data,10, max_iter=100,mode=2)\n",
    "Jaccard_SSE = model2.calculate_SSE(centroids2,clusters2,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f937956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacard SSE: 34364573698.62264\n"
     ]
    }
   ],
   "source": [
    "print(\"Jacard SSE:\",Jaccard_SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de5abb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 3, 7, 4, 5, 7, 3, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_labels2 = predict_cluster_labels(centroids2,clusters2,labels)\n",
    "cluster_labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ff1c310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.215"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_Jaccard = accuracy(centroids2, cluster_labels2,test_data,test_labels)\n",
    "Accuracy_Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3b1698c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerance for the Iteration  0 :  30447.858235294116\n",
      "Tolerance for the Iteration  1 :  8563.813767929267\n",
      "Tolerance for the Iteration  2 :  3053.729866962306\n",
      "Tolerance for the Iteration  3 :  1497.5509278801605\n",
      "Tolerance for the Iteration  4 :  826.453798270031\n",
      "Tolerance for the Iteration  5 :  630.2447496434121\n",
      "Tolerance for the Iteration  6 :  705.1632621272804\n",
      "Tolerance for the Iteration  7 :  784.2842579750347\n",
      "Tolerance for the Iteration  8 :  599.9003316534498\n",
      "Tolerance for the Iteration  9 :  589.0188097745022\n",
      "Tolerance for the Iteration  10 :  479.0917602374152\n",
      "Tolerance for the Iteration  11 :  484.5633739766883\n",
      "Tolerance for the Iteration  12 :  459.4042003805322\n",
      "Tolerance for the Iteration  13 :  370.5925043401301\n",
      "Tolerance for the Iteration  14 :  199.13709677419382\n",
      "Tolerance for the Iteration  15 :  151.43453968253968\n",
      "Tolerance for the Iteration  16 :  155.51282636745916\n",
      "Tolerance for the Iteration  17 :  109.72090729783035\n",
      "Tolerance for the Iteration  18 :  96.28662504465058\n",
      "Tolerance for the Iteration  19 :  95.51222829236639\n",
      "Tolerance for the Iteration  20 :  109.78479574361623\n",
      "Tolerance for the Iteration  21 :  115.5490885416667\n",
      "Tolerance for the Iteration  22 :  138.7005634548033\n",
      "Tolerance for the Iteration  23 :  163.0389585934867\n",
      "Tolerance for the Iteration  24 :  108.36039076664083\n",
      "Tolerance for the Iteration  25 :  116.01928945371553\n",
      "Tolerance for the Iteration  26 :  105.0097184172153\n",
      "Tolerance for the Iteration  27 :  81.56943671527034\n",
      "Tolerance for the Iteration  28 :  92.48747215705208\n",
      "Tolerance for the Iteration  29 :  66.57164760697977\n",
      "Tolerance for the Iteration  30 :  42.257228315054775\n",
      "Tolerance for the Iteration  31 :  56.047861405802706\n",
      "Tolerance for the Iteration  32 :  54.1643197122239\n",
      "Tolerance for the Iteration  33 :  41.04307058843445\n",
      "Tolerance for the Iteration  34 :  49.77409131247621\n",
      "Tolerance for the Iteration  35 :  36.39350368857566\n",
      "Tolerance for the Iteration  36 :  34.71156255067549\n",
      "Tolerance for the Iteration  37 :  35.668219741051516\n",
      "Tolerance for the Iteration  38 :  35.55072512771122\n",
      "Tolerance for the Iteration  39 :  34.654974707748075\n",
      "Tolerance for the Iteration  40 :  0.0\n"
     ]
    }
   ],
   "source": [
    "model3 = KMeans()\n",
    "centroids3,clusters3 = model3.train_Kmeans(data,10, max_iter = 100,mode=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38b6e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cosine_SSE = model3.calculate_SSE(centroids3,clusters3,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0460d72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean SSE: 25454304340.476444\n",
      "Jacard SSE: 34364573698.62264\n",
      "Cosine SSE : 25430375772.008137\n"
     ]
    }
   ],
   "source": [
    "print(\"Euclidean SSE:\",Euclidean_SSE)\n",
    "print(\"Jacard SSE:\",Jaccard_SSE)\n",
    "print(\"Cosine SSE :\",Cosine_SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7b53efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 6, 2, 1, 8, 7, 5, 0, 3, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_labels3 = predict_cluster_labels(centroids3,clusters3,labels)\n",
    "cluster_labels3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83da6ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_Cosine = accuracy(centroids3, cluster_labels3,test_data,test_labels)\n",
    "Accuracy_Euclidean\n",
    "Accuracy_Jaccard\n",
    "Accuracy_Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a0617d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean accuracy: 0.645\n",
      "Jacard accuracy: 0.215\n",
      "Cosine accuracy : 0.63\n"
     ]
    }
   ],
   "source": [
    "print(\"Euclidean accuracy:\",Accuracy_Euclidean)\n",
    "print(\"Jacard accuracy:\",Accuracy_Jaccard)\n",
    "print(\"Cosine accuracy :\",Accuracy_Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfc02e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    \n",
    "    def calculate_SSE(self, centroid_value_dict, centroid_dict, data):\n",
    "        sse_data = 0\n",
    "        for i in centroid_dict:\n",
    "            sse_cluster = 0\n",
    "            for j in centroid_dict[i]:\n",
    "                dp = list(data.iloc[int(j)])\n",
    "                for a, b in zip(centroid_value_dict[i], dp):\n",
    "                    sse_cluster += (a - b) ** 2\n",
    "            sse_data += sse_cluster\n",
    "        return sse_data\n",
    "    \n",
    "    def Initialize_Centroids(self, data, K):\n",
    "        m = data.shape[0]\n",
    "        centroid_value_dict = {}\n",
    "        for i in range(K):\n",
    "            r = np.random.randint(0, m-1)\n",
    "            centroid_value_dict[i] = data.iloc[r]\n",
    "        return centroid_value_dict\n",
    "    \n",
    "    def jaccard_similarity(self, centroid, dp):\n",
    "        intersection = len(list(set(centroid).intersection(dp)))\n",
    "        union = (len(set(centroid)) + len(set(dp))) - intersection\n",
    "        return float(intersection) / union\n",
    "\n",
    "    def train_Kmeans(self, data, K, max_iter=20, mode=1, tol=10, stopping_condition='centroid_change'):\n",
    "        # Mode = 1 => Euclidean np.linalg.norm(x-list(data.iloc[i,:]))\n",
    "        # Mode = 2 => Jaccard\n",
    "        # Mode = 3 => Cosine\n",
    "        centroid_value_dict = self.Initialize_Centroids(data, K)\n",
    "        new_centroid_value_dict = {}\n",
    "        count = 0\n",
    "        centroid_dict = {}\n",
    "        sse_list = []\n",
    "        convergence = False\n",
    "        \n",
    "        while (count < max_iter) and not convergence:\n",
    "            \n",
    "            for i in list(centroid_value_dict.keys()):\n",
    "                centroid_dict[i] = []\n",
    "                \n",
    "            for i in range(data.shape[0]):\n",
    "                x = data.iloc[i]\n",
    "                if mode == 1:\n",
    "                    distance_measure = [np.linalg.norm(x - centroid_value_dict[j]) for j in centroid_value_dict]\n",
    "                    idx = np.argmin(distance_measure)\n",
    "                    centroid_dict[idx].append(i)\n",
    "                elif mode == 2:\n",
    "                    distance_measure = [self.jaccard_similarity(list(x), centroid_value_dict[j]) for j in centroid_value_dict]\n",
    "                    idx = np.argmax(distance_measure)\n",
    "                    centroid_dict[idx].append(i)\n",
    "                elif mode == 3:\n",
    "                    distance_measure = [1 - scipy.spatial.distance.cosine(x, list(centroid_value_dict[j])) for j in centroid_value_dict]\n",
    "                    idx = np.argmax(distance_measure)\n",
    "                    centroid_dict[idx].append(i)\n",
    "                \n",
    "                prev_centroids = dict(centroid_value_dict)\n",
    "            \n",
    "            for i in centroid_dict:\n",
    "                if len(centroid_dict[i]):\n",
    "                    dps_centroid = centroid_dict[i]\n",
    "                    centroid_value_dict[i] = np.average(data.iloc[dps_centroid], axis=0)\n",
    "            \n",
    "            current_tol = -1\n",
    "            for i in centroid_value_dict:\n",
    "                prev_centroid_point = prev_centroids[i]\n",
    "                new_centroid_point = centroid_value_dict[i]\n",
    "                change = np.sum(np.absolute(new_centroid_point - prev_centroid_point))\n",
    "                current_tol = max(change, current_tol)\n",
    "                \n",
    "            sse = self.calculate_SSE(centroid_value_dict, centroid_dict, data)\n",
    "            sse_list.append(sse)\n",
    "            \n",
    "            if stopping_condition == 'centroid_change' and current_tol < tol:\n",
    "                convergence = True\n",
    "                break\n",
    "            \n",
    "            if stopping_condition == 'sse_increase' and len(sse_list) > 1 and sse_list[-1] > sse_list[-2]:\n",
    "                convergence = True\n",
    "                break\n",
    "                \n",
    "            count += 1\n",
    "            if stopping_condition == 'max_iter' and count == max_iter:\n",
    "                convergence = True\n",
    "                break\n",
    "\n",
    "                \n",
    "        return centroid_value_dict, centroid_dict, sse_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edda70b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans()\n",
    "\n",
    "# Train Euclidean-K-means\n",
    "centroids_euc, clusters_euc, sse_list_euc = model.train_Kmeans(data, K=10, max_iter=100, mode=1, tol=10, stopping_condition='centroid_change')\n",
    "\n",
    "# Train Jaccard-K-means\n",
    "centroids_jac, clusters_jac, sse_list_jac = model.train_Kmeans(data, K=10, max_iter=100, mode=2, tol=10, stopping_condition='centroid_change')\n",
    "\n",
    "# Train Cosine-K-means\n",
    "centroids_cos, clusters_cos, sse_list_cos = model.train_Kmeans(data, K=10, max_iter=100, mode=3, tol=10, stopping_condition='centroid_change')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae55c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
